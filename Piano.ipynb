{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dense,Dropout,Activation,LSTM\n",
    "from keras.models import Model,Sequential\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import stream\n",
    "from music21 import converter, instrument,note,chord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading File No.: 1\n",
      "Reading File No.: 2\n",
      "Reading File No.: 3\n",
      "Reading File No.: 4\n",
      "Reading File No.: 5\n",
      "Reading File No.: 6\n",
      "Reading File No.: 7\n",
      "Reading File No.: 8\n",
      "Reading File No.: 9\n",
      "Reading File No.: 10\n",
      "Reading File No.: 11\n",
      "Reading File No.: 12\n",
      "Reading File No.: 13\n",
      "Reading File No.: 14\n",
      "Reading File No.: 15\n",
      "Reading File No.: 16\n",
      "Reading File No.: 17\n",
      "Reading File No.: 18\n",
      "Reading File No.: 19\n",
      "Reading File No.: 20\n",
      "Reading File No.: 21\n",
      "Reading File No.: 22\n",
      "Reading File No.: 23\n",
      "Reading File No.: 24\n",
      "Reading File No.: 25\n",
      "Reading File No.: 26\n",
      "Reading File No.: 27\n",
      "Reading File No.: 28\n",
      "Reading File No.: 29\n",
      "Reading File No.: 30\n",
      "Reading File No.: 31\n",
      "Reading File No.: 32\n",
      "Reading File No.: 33\n",
      "Reading File No.: 34\n",
      "Reading File No.: 35\n",
      "Reading File No.: 36\n",
      "Reading File No.: 37\n",
      "Reading File No.: 38\n",
      "Reading File No.: 39\n",
      "Reading File No.: 40\n",
      "Reading File No.: 41\n",
      "Reading File No.: 42\n",
      "Reading File No.: 43\n",
      "Reading File No.: 44\n",
      "Reading File No.: 45\n",
      "Reading File No.: 46\n",
      "Reading File No.: 47\n",
      "Reading File No.: 48\n",
      "Reading File No.: 49\n",
      "Reading File No.: 50\n",
      "Reading File No.: 51\n",
      "Reading File No.: 52\n",
      "Reading File No.: 53\n",
      "Reading File No.: 54\n",
      "Reading File No.: 55\n",
      "Reading File No.: 56\n",
      "Reading File No.: 57\n",
      "Reading File No.: 58\n",
      "Reading File No.: 59\n",
      "Reading File No.: 60\n",
      "Reading File No.: 61\n",
      "Reading File No.: 62\n",
      "Reading File No.: 63\n",
      "Reading File No.: 64\n",
      "Reading File No.: 65\n",
      "Reading File No.: 66\n",
      "Reading File No.: 67\n",
      "Reading File No.: 68\n",
      "Reading File No.: 69\n",
      "Reading File No.: 70\n",
      "Reading File No.: 71\n",
      "Reading File No.: 72\n",
      "Reading File No.: 73\n",
      "Reading File No.: 74\n",
      "Reading File No.: 75\n",
      "Reading File No.: 76\n",
      "Reading File No.: 77\n",
      "Reading File No.: 78\n",
      "Reading File No.: 79\n",
      "Reading File No.: 80\n",
      "Reading File No.: 81\n",
      "Reading File No.: 82\n",
      "Reading File No.: 83\n",
      "Reading File No.: 84\n",
      "Reading File No.: 85\n",
      "Reading File No.: 86\n",
      "Reading File No.: 87\n",
      "Reading File No.: 88\n",
      "Reading File No.: 89\n",
      "Reading File No.: 90\n",
      "Reading File No.: 91\n",
      "Reading File No.: 92\n"
     ]
    }
   ],
   "source": [
    "#Reading Files from midi songs folder -----------------Here we extract notes from the audio files and \n",
    "#append all the notes list notes[]\n",
    "notes=[]\n",
    "i=1\n",
    "for file in glob.glob(\"C:/Users/user/cpc/midi_songs/*.mid\"):\n",
    "    print(\"Reading File No.:\", i)\n",
    "    i+=1\n",
    "    midi= converter.parse(file)        #Parses the file audio\n",
    "    #print(midi)\n",
    "    notes_to_parse=[]\n",
    "    parts=instrument.partitionByInstrument(midi)  # Extract the piano tunes\n",
    "    #print(parts)\n",
    "    if parts:\n",
    "        notes_to_parse=parts.parts[0].recurse()\n",
    "    else:                                             #if there are piano tunes we recurse else include flat notes\n",
    "        notes_to_parse= midi.flat_notes\n",
    "        \n",
    "    #print(notes_to_parse)\n",
    "    for element in notes_to_parse:\n",
    "        if isinstance(element, note.Note):               #For every tune of notes we extract notes and chords\n",
    "            notes.append(str(element.pitch))\n",
    "        elif isinstance( element, chord.Chord):\n",
    "            notes.append('.'.join(str(n) for n in element.normalOrder))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4.9', 'E2', '4.9', '4.9']\n"
     ]
    }
   ],
   "source": [
    "print(notes[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len=100\n",
    "pitchnames=sorted(set(item for item in notes))          #Extracting sorted and unique notes\n",
    "note2int = dict((note,number) for number,note in enumerate(pitchnames))      #Vocab for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_i=[]\n",
    "net_o=[]\n",
    "# Here we create our examples for training which consisits of 100 length of notes and the next note as its target\n",
    "# We also tokenize our input examples using vocab note2int\n",
    "for i in range(0,len(notes)-seq_len,1):\n",
    "    seqi=notes[i:i+seq_len]\n",
    "    #print(seqi)\n",
    "    seqo=notes[i+seq_len]\n",
    "    #print(seqi)\n",
    "    #print(seqo)\n",
    "    \n",
    "    net_i.append([note2int[t] for t in seqi])\n",
    "    \n",
    "    net_o.append([note2int[seqo]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_patterns=len(net_i)\n",
    "n_vocab=len(note2int)\n",
    "net_i= np.reshape(net_i,(n_patterns,seq_len,1))\n",
    "net_i=net_i/float(n_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_o=to_categorical(net_o)\n",
    "net_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57077, 358)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(net_o.shape)\n",
    "print(net_i.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 100, 512)          1052672   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100, 512)          0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 100, 512)          2099200   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100, 512)          0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 358)               92006     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 358)               0         \n",
      "=================================================================\n",
      "Total params: 5,474,406\n",
      "Trainable params: 5,474,406\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Creating our Deep Learning Model\n",
    "\n",
    "def make_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512,input_shape=(net_i.shape[1], net_i.shape[2]),return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(512, return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(512, return_sequences=False))\n",
    "    model.add(Dense(256))#activation='relu')\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))#,activation='softmax')\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint created Keeps track of weights after every epoch \n",
    "filepath = \"weights-improvement-={epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "checkpoint = ModelCheckpoint(\n",
    "        filepath,\n",
    "        monitor='loss',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    )\n",
    "callbacks_list = [checkpoint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Model was trained for 10 hrs on a GPU on kaggle kernel for 80 epochs after which I managed to get an accuracy of approx\n",
    "#  88% which is not bad i guess\n",
    "\n",
    "model.load_weights('../pianofiles/3lstm_65_acc_88.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(net_i, net_o, epochs=1, batch_size=64,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"weights_epoch80_acc_82.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now that we have trained our model we now try to predict the tunes\n",
    "\n",
    "start= np.random.randint(0,len(net_i)-1) # Take a random sample from input\n",
    "pattern= net_i[start]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "int2not2=dict((note2int[x],x) for x in note2int) #Reverse vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_out=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WE predict the next 100 note based on the given pattern \n",
    "\n",
    "for ni in range(100):\n",
    "    predi=np.reshape(pattern,(1,len(pattern),1))  #Reshape the given pattern\n",
    "    prediction= model.predict(predi)               #Obtain the predicted outputs\n",
    "    i=np.argmax(prediction)                            #Get the best note with maximum value\n",
    "    res=int2not2[i]                              \n",
    "    pred_out.append(res)                           #Append the note to output notes\n",
    "    \n",
    "    pattern=np.append(pattern,i/len(note2int)) \n",
    "    pattern=pattern[1:]                            #Since pattern has increased by 1 note we ignore the 1st note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "print(len(pred_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_out[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now that we have created the output notes from model we need to convert it into\n",
    "# actual notes for midi file as they are currently in string\n",
    "offset = 0\n",
    "output_notes = []\n",
    "\n",
    "for pattern in pred_out:\n",
    "    #If its a chord like 3.4 or 6.4.2\n",
    "    if(('.' in pattern) or pattern.isdigit()):\n",
    "        \n",
    "        \n",
    "        notesinchord=pattern.split(\".\")\n",
    "        notes=[]\n",
    "        for cur in notesinchord:                              #set parameters of the chord\n",
    "            newnote=note.Note(int(cur))\n",
    "            newnote.storedInstrument=instrument.Piano()\n",
    "            notes.append(newnote)\n",
    "        newchord= chord.Chord(notes)\n",
    "        newchord.offset= offset\n",
    "        output_notes.append(newchord)\n",
    "    else:                                                  #else if pattern is a note simply append it as note\n",
    "        newnote=note.Note(pattern)\n",
    "        newnote.offset = offset\n",
    "        newnote.storedInstrument = instrument.Piano()\n",
    "        output_notes.append(newnote)\n",
    "    \n",
    "    offset+=1.0                                     #Offset keeps track of time between two note play\n",
    "                                                    #Like offset 1.0 here tells that after each noteplay theres a gap of 1s\n",
    "    \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/user/predction.mid'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Congrats you're all set you just predicted a tone from a input example \n",
    "#Now only thing remaining is to convert in into a midi file for listening it\n",
    "#which can be easily done by streams\n",
    "\n",
    "midistream= stream.Stream(output_notes)\n",
    "midistream.write('midi',fp='C:/Users/user/predction.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
